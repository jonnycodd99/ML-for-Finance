# Convert back to sf dataframe
court_left <- court_lines_in
for(i in 1:11) {
court_left$geom[i] <- court_lines_rotated[[i]]
court_left$geom[i] <- st_geometry(court_left$geom[i]) + c(0, 25) # shift up
court_left$Feature[i] <- paste0(court_left$Feature[i], " L")
}
# Make right side of court
# rotate 90 degrees
st_geometry(court_lines_in) * matrix(c(0, -1, 1, 0), ncol = 2) -> court_lines_right_rotated
# Convert back to sf dataframe
court_right <- court_lines_in
for(i in 1:11) {
court_right$geom[i] <- court_lines_right_rotated[[i]]
court_right$geom[i] <- st_geometry(court_right$geom[i]) + c(94, 25) # shift up and right
court_right$Feature[i] <- paste0(court_right$Feature[i], " R")
}
# Full court
full_court <- bind_rows(court_left, court_right)
ggplot(full_court) +
geom_sf() +
theme_minimal()
court_lines_right_rotated<-NULL
court_lines_rotated<-NULL
View(court_lines_in)
library(sf)
rm(list=ls())
DIR <- '.'
# Load in court lines
court_lines_in <- st_read(file.path(DIR, "data/nba-court-lines-05feb2024.gpkg"),  layer = "nba-court-lines-05feb2024")
court_lines_in <- court_lines_in[-1, ]
# Make left side of court
# rotate 90 degrees
st_geometry(court_lines_in) * matrix(c(0, 1, -1, 0), ncol = 2) -> court_lines_rotated
# Convert back to sf dataframe
court_left <- court_lines_in
for(i in 1:11) {
court_left$geom[i] <- court_lines_rotated[[i]]
court_left$geom[i] <- st_geometry(court_left$geom[i]) + c(0, 25) # shift up
court_left$Feature[i] <- paste0(court_left$Feature[i], " L")
}
court_lines_rotated<-NULL
# Make right side of court
# rotate 90 degrees
st_geometry(court_lines_in) * matrix(c(0, -1, 1, 0), ncol = 2) -> court_lines_right_rotated
# Convert back to sf dataframe
court_right <- court_lines_in
for(i in 1:11) {
court_right$geom[i] <- court_lines_right_rotated[[i]]
court_right$geom[i] <- st_geometry(court_right$geom[i]) + c(94, 25) # shift up and right
court_right$Feature[i] <- paste0(court_right$Feature[i], " R")
}
court_lines_right_rotated<-NULL
# Full court
full_court <- bind_rows(court_left, court_right)
ggplot(full_court) +
geom_sf() +
theme_minimal()
DATA_DIR <- "./data"
file <- "0021500622.json"
# Read file
json_data <- fromJSON(file.path(DATA_DIR, file))
# PLAYERS
players <- get_players_info(json_data)
library(jsonlite)
library(data.table)
library(dplyr)
library(progress)
source("helper_functions.R")
DATA_DIR <- "./data"
file <- "0021500622.json"
# Read file
json_data <- fromJSON(file.path(DATA_DIR, file))
library(jsonlite)
library(data.table)
library(dplyr)
library(progress)
source("helper_functions.R")
source("helper_functions.R")
# BALL
get_ball <- function(data) {
return(data.frame(x = data[3], y=data[4]))
}
# PLAYERS
get_players <- function(data) {
return(data.frame(player_id=data[2:nrow(data),2], x = data[2:nrow(data),3], y=data[2:nrow(data),4]))
}
# PLAYERS
get_players_info <- function(json_data) {
home_players <- json_data$events$home$players[[1]]
visitor_players <- json_data$events$visitor$players[[1]]
home_players$team <- "home"
visitor_players$team <- "visitor"
return(rbind(home_players, visitor_players))
}
# MOMENT INFO
get_moment_info <- function(id_play, moment, ball_positions, players_positions) {
clock <- if (is.null(moment[[4]])) { 0 } else { moment[[4]] }
metadata <- data.frame(play_id = id_play,  moment_id = as.character(moment[[2]]), time=moment[[3]], clock=clock)
ball_positions <- rbind(ball_positions,
cbind( metadata, get_ball(moment[[6]][1,]))
)
players_positions <- rbind(players_positions,
cbind(metadata, get_players(moment[[6]]))
)
return(list(ball_positions, players_positions))
}
DATA_DIR <- "./data"
file <- "0021500622.json"
# Read file
json_data <- fromJSON(file.path(DATA_DIR, file))
# PLAYERS
players <- get_players_info(json_data)
# PLAYS
plays <- json_data$events$moments
# BALL + PLAYERS
ball_positions <- data.frame(play_id=NULL, moment_id=NULL, time=NULL, clock=NULL, x=NULL, y=NULL)
players_positions <- data.frame(play_id=NULL, moment_id=NULL, time=NULL, clock=NULL, player_id=NULL, x=NULL, y=NULL)
# progress_bar
total_iterations <- length(plays)
# Initialize progress bar
pb <- progress_bar$new(
format = "[:bar] :percent ETA: :eta",
total = total_iterations
)
for (id_play in seq(length(plays))) {
moments <- plays[[id_play]]
#print(id_play)
if (length(moments) > 0) {
for (id_moment in seq(length(moments))) {
moment <- plays[[id_play]][[id_moment]]
res <- get_moment_info(id_play, moment, ball_positions, players_positions)
ball_positions <- res[[1]]
players_positions <- res[[2]]
}
}
pb$tick()
}
# Close progress bar
pb$close()
# POINTS - Get last possesion
ball_last_possession <- data.table(ball_positions)[, .SD[.N], by = play_id]
players_last_possesion <- merge(ball_last_possession,
data.table(players_positions)[moment_id %in% last_possesion$moment_id],
by=c("play_id", "moment_id"),
all.x=T, allow.cartesian = T, suffixes = c("_ball", ""))
# Calculate distance between each player and the ball
players_last_possesion[, distance_ball := sqrt((x - x_ball)^2 + (y - y_ball)^2)]
# Find the player closest to the ball (the shooter)
shooters <- merge(
players_last_possesion[, .SD[which.min(distance_ball)], by = play_id],
data.table(players), by.x='player_id', by.y='playerid', all.x=T, all.y=F
) %>% select(play_id, time, clock, x, y, distance_ball, lastname, firstname, jersey, team) %>% arrange(time)
# Packages
rm(list=ls())
library(data.table)
library(dplyr)
library(progress)
library(sf)
library(ggplot2)
library(paletteer)
library(stringr)
# Directory
DATA_DIR <- "./data"
# Load Courts data
full_court <- st_read(file.path(DATA_DIR, "nba-court-lines-05feb2024.gpkg"),  layer = "nba-court-lines-05feb2024")
half_court <- full_court[-1, ]
# Create the basketball court plot
court_plot <- ggplot() +
geom_sf(data = half_court, color = "black", fill = "transparent", linewidth= 1)  # Increase line thickness here
court_plot
# Load shots data
shots_data <- data.table()
for (year in 2004:2023) {
file_name <- sprintf("NBA_%d_Shots.csv", year)
year_data <- fread(file.path(DATA_DIR, file_name))
shots_data <- rbindlist(list(shots_data, year_data), use.names = TRUE, fill = TRUE)
}
# Directory
DATA_DIR <- "./data"
# Load Courts data
full_court <- st_read(file.path(DATA_DIR, "nba-court-lines-05feb2024.gpkg"),  layer = "nba-court-lines-05feb2024")
half_court <- full_court[-1, ]
# Create the basketball court plot
court_plot <- ggplot() +
geom_sf(data = half_court, color = "black", fill = "transparent", linewidth= 1)  # Increase line thickness here
court_plot
# Load shots data
shots_data <- data.table()
for (year in 2004:2023) {
file_name <- sprintf("NBA_%d_Shots.csv", year)
year_data <- fread(file.path(DATA_DIR, file_name))
shots_data <- rbindlist(list(shots_data, year_data), use.names = TRUE, fill = TRUE)
}
# Packages
rm(list=ls())
library(data.table)
library(dplyr)
library(progress)
library(sf)
library(ggplot2)
library(paletteer)
library(stringr)
# Directory
DATA_DIR <- "./data"
# Load Courts data
full_court <- st_read(file.path(DATA_DIR, "nba-court-lines-05feb2024.gpkg"),  layer = "nba-court-lines-05feb2024")
half_court <- full_court[-1, ]
# Create the basketball court plot
court_plot <- ggplot() +
geom_sf(data = half_court, color = "black", fill = "transparent", linewidth= 1)  # Increase line thickness here
court_plot
# Load shots data
shots_data <- data.table()
for (year in 2004:2023) {
file_name <- sprintf("NBA_%d_Shots.csv", year)
year_data <- fread(file.path(DATA_DIR, file_name))
shots_data <- rbindlist(list(shots_data, year_data), use.names = TRUE, fill = TRUE)
}
for (year in 2005:2023) {
file_name <- sprintf("NBA_%d_Shots.csv", year)
year_data <- fread(file.path(DATA_DIR, file_name))
shots_data <- rbindlist(list(shots_data, year_data), use.names = TRUE, fill = TRUE)
}
# Directory
DATA_DIR <- "/Users/jonnycodd/Documents/MASTERS/Geo spacial/NBA Project/data"
for (year in 2004:2023) {
file_name <- sprintf("NBA_%d_Shots.csv", year)
year_data <- fread(file.path(DATA_DIR, file_name))
shots_data <- rbindlist(list(shots_data, year_data), use.names = TRUE, fill = TRUE)
}
# HEAT MAP
################################################################################
shots_2010_curry <- shots_data %>%
filter(SEASON_1 == 2009) %>%
filter(str_detect(PLAYER_NAME, "Stephen Curry"))
steph_curry_2010 <- ggplot() +
geom_sf(data = half_court, color = "black", fill = "transparent", linewidth= 1) +
geom_density_2d_filled(shots_2010_curry, mapping = aes(x = LOC_X, y = LOC_Y,fill = ..level..,),  adjust = 1,
contour_var = "ndensity", breaks = seq(0.1, 1.0, length.out = 10), alpha = .8)  +
scale_x_continuous(limits = c(-27.5, 27.5)) +
scale_y_continuous(limits = c(0, 45)) +
theme(legend.position = "none",
axis.title.x = element_blank(),
axis.title.y = element_blank(),
axis.text.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank())
steph_curry_2010
# Load Courts data
full_court <- st_read(file.path(DATA_DIR, "nba-court-lines-05feb2024.gpkg"),  layer = "nba-court-lines-05feb2024")
half_court <- full_court[-1, ]
# Create the basketball court plot
court_plot <- ggplot() +
geom_sf(data = half_court, color = "black", fill = "transparent", linewidth= 1)  # Increase line thickness here
court_plot
# Load shots data
shots_data <- data.table()
for (year in 2004:2023) {
file_name <- sprintf("NBA_%d_Shots.csv", year)
year_data <- fread(file.path(DATA_DIR, file_name))
shots_data <- rbindlist(list(shots_data, year_data), use.names = TRUE, fill = TRUE)
}
# Make SF point object
shots_data_sf <- st_as_sf(shots_data, coords = c("LOC_X", "LOC_Y"), crs = 4326)
# SHOT SUCESS RATE BY DISTANCE
################################################################################
# Extract the hoop location
hoop_location <- half_court %>%
filter(Feature == "Hoop") %>%
st_geometry()
# Calculate distance to hoop
shot_distances <- st_distance(shots_data_sf, hoop_location)
data <- readRDS("data\WorldMarkts99_20.RDS")
data <- readRDS("WorldMarkts99_20.RDS")
data <- readRDS("data\WorldMarkts99_20.RDS")
data <- readRDS("data/WorldMarkts99_20.RDS")
View(data)
readRDS("data/WorldMarkts99_20.RDS")
load("data/WorldMarkts99_20.RDS")
load('data/WorldMarkts99_20.RDS')
rm(list=ls())
load('data/WorldMarkts99_20.RDS')
# Load data
world_markets_data <- readRDS('data/WorldMarkts99_20.RDS')
View(world_markets_data)
world_markets_data$BSESN
BSESN <- world_markets_data$BSESN
View(BSESN)
world_markets_data$BSESN
print(names(my_environment))
print(names(world_markets_data))
list2env(world_markets_data, envir = .GlobalEnv)
print(names(world_markets_data))
world_markets_data$BSESN
twii_data <- world_markets_data[["TWII"]]
View(twii_data)
world_markets_data[["TWII"]]
world_markets_data[["TWII.Open"]]
world_markets_data$BSESN.Open
world_markets_data$BSESN
View(twii_data)
twii_df <- as.data.frame(world_markets_data[["TWII"]])
View(twii_df)
bsesn_df <- as.data.frame(world_markets_data$BSESN)
View(twii_data)
load("/Users/jonnycodd/Documents/MASTERS/ML for Finance/ML-for-Finance homeworks/Homework 1/data/WorldMarkts99_20.RDS")
##in case you don't have install AER :
USMoney = readRDS("/Users/jonnycodd/Documents/MASTERS/ML for Finance/R Labs/USMoney.rds"); ##from AER
##Is corr motive for causation? see plots and corr:
plot(USMoney)
cor(USMoney)
## C. Sims experiment:
##To know if money causes gnp
grangertest(gnp~m1, order=3,data=USMoney)
##To know if gnp causes money
grangertest(m1~gnp, order=3,data=USMoney)
rm(list=ls())
bsesn<-world_markets_data$BSESN
# Load data
world_markets_data <- readRDS('data/WorldMarkts99_20.RDS')
bsesn<-world_markets_data$BSESN
plot(bsesn)
world_markets_data$BSESN
View(bsesn)
world_markets_data[["TWII"]]
class(bsesn)
str(bsesn)
bsesn_df <- data.frame(date = index(bsesn), as.data.frame(bsesn))
bsesn_df <- data.frame(date = index(bsesn), as.data.frame(bsesn))
bsesn_df <- data.frame(date = index(bsesn), as.data.frame(bsesn))
library(xts)
bsesn_df <- data.frame(date = index(bsesn), as.data.frame(bsesn))
View(bsesn_df)
##################################
##Argimiro Arratia @2023 Computational Finance
##Rlab to aid Task  Causality Analysis for World Markets
##################################
library(xts); library(quantmod); library(plyr)
library("vars")
##Optional: to retrieve fresh market data
mktsym<- c("^BSESN", "^BVSP","^FTSE","^GDAXI","^GSPC","^HSCE",
"^IBEX","^JKSE","^MXX","^N225","^TWII","^VLIC","^VIX")
marktCtry<-c("India", "Brazil","UK","Germany","USA","China-Shanghai",
"Spain","Indonesia","Mexico","Japan","Taiwan","VLIC","VIX")
dateI="1999-01-01"; dateF="2020-04-30"
#Get data from yahoo finance
data.env<-new.env()
l_ply(mktsym, function(sym) try(getSymbols(sym,src="yahoo",from=dateI,to=dateF,env=data.env),silent=T))
##Optional: save in disc historic data for this portfolio
saveRDS(data.env,file="WorldMarkts99_20.RDS")
##Start HW1 from here
### Get data from disc
data.env <- readRDS("../data/2/WorldMarkts99_20.RDS")
View(data.env)
### loop through to get Ad.Close, compute weekly return and merge all stocks and treat as xts objects
returns <- xts()
per<- "weekly" ## "monthly", "daily"##period of sampling
for(i in seq_along(markets)) {
sym <- markets[i]
returns <- merge(returns,
periodReturn(Ad(get(sym,envir=data.env)),period=per,type = "log"))
#periodReturn(Op(get(sym,envir=data.env)),period=per,type = "arithmetic"))
}
##################################
##Argimiro Arratia @2023 Computational Finance
##Rlab to aid Task  Causality Analysis for World Markets
##################################
library(xts); library(quantmod); library(plyr)
library("vars")
##Optional: to retrieve fresh market data
mktsym<- c("^BSESN", "^BVSP","^FTSE","^GDAXI","^GSPC","^HSCE",
"^IBEX","^JKSE","^MXX","^N225","^TWII","^VLIC","^VIX")
marktCtry<-c("India", "Brazil","UK","Germany","USA","China-Shanghai",
"Spain","Indonesia","Mexico","Japan","Taiwan","VLIC","VIX")
dateI="1999-01-01"; dateF="2020-04-30"
#Get data from yahoo finance
data.env<-new.env()
l_ply(mktsym, function(sym) try(getSymbols(sym,src="yahoo",from=dateI,to=dateF,env=data.env),silent=T))
##Optional: save in disc historic data for this portfolio
saveRDS(data.env,file="WorldMarkts99_20.RDS")
##Start HW1 from here
### Get data from disc
data.env <- readRDS("../data/2/WorldMarkts99_20.RDS")
markets <- ls(data.env)
### loop through to get Ad.Close, compute weekly return and merge all stocks and treat as xts objects
returns <- xts()
per<- "weekly" ## "monthly", "daily"##period of sampling
for(i in seq_along(markets)) {
sym <- markets[i]
returns <- merge(returns,
periodReturn(Ad(get(sym,envir=data.env)),period=per,type = "log"))
#periodReturn(Op(get(sym,envir=data.env)),period=per,type = "arithmetic"))
}
View(returns)
rm(list=ls())
# Packages
library(xts)
library("TTR")
library(tidyverse)
library(ggplot2)
library(reshape2)
## Set working directory to current script's location.
fileloc <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(fileloc)
rm(fileloc)
## Load data
world_markets_data <- readRDS('data/WorldMarkts99_20.RDS')
## Extract BSESN data
bsesn <-world_markets_data$BSESN
## Get subset of data
bsesn_df <- bsesn['2015-04/2017-03']; m=length(bsesn_df$BSESN.Open);
bsesn_ophlc <- bsesn_df[,c("BSESN.Open","BSESN.High","BSESN.Low","BSESN.Close")]
# Fill in missing values with previous value
bsesn_ophlc$BSESN.Open <- zoo::na.locf(bsesn_ophlc$BSESN.Open, na.rm = FALSE)
bsesn_ophlc$BSESN.High <- zoo::na.locf(bsesn_ophlc$BSESN.High, na.rm = FALSE)
bsesn_ophlc$BSESN.Low <- zoo::na.locf(bsesn_ophlc$BSESN.Low, na.rm = FALSE)
bsesn_ophlc$BSESN.Close <- zoo::na.locf(bsesn_ophlc$BSESN.Close, na.rm = FALSE)
## Calculate volatility (regular estimations)
######################
vClose <- TTR::volatility(bsesn_ophlc, n=252,calc="close",N=252)
vParkinson <- TTR::volatility(bsesn_ophlc, n= 252,calc="parkinson",N=252)
vGK <- TTR::volatility(bsesn_ophlc, n= 252,calc="garman",N=252)
## Calculate EMA using TTR
######################
returns <-diff(bsesn_ophlc$BSESN.Close)
log_returns <- diff(log(bsesn_ophlc$BSESN.Close))
log_returns_squared <- log_returns^2
vEMA <- TTR::EMA(log_returns, ratio=0.06, N=252)
vEMA <- sqrt(vEMA) * sqrt(252)  # Convert to annualized volatility
vEMA[m] # 0.09
# Create a data frame of results
volatility_measures <- data.frame(
Close = vClose[m],
Parkinson = vParkinson[m],
Garman_Klass = vGK[m],
EMA = vEMA[m]
)
print(volatility_measures)
# Combine the xts objects into a single xts object
combined_xts <- merge(vClose, vParkinson, vGK, vEMA)
combined_xts <- combined_xts['2016-04/2017-03']
# Convert the xts object to a data frame for ggplot
df_combined <- data.frame(Date = index(combined_xts), coredata(combined_xts))
# Melt the data frame for ggplot2
df_melted <- melt(df_combined, id = "Date")
# Plot using ggplot2
ggplot(df_melted, aes(x = Date, y = value, color = variable)) +
geom_line() +
labs(title = "Volatity of BSESN",
x = "Date", y = "Value", color = "Variables") +
theme_minimal()
rm(list=ls())
# Packages
library(xts)
library("TTR")
library(tidyverse)
library(ggplot2)
library(reshape2)
## Set working directory to current script's location.
fileloc <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(fileloc)
rm(fileloc)
## Load data
world_markets_data <- readRDS('data/WorldMarkts99_20.RDS')
## Extract BSESN data
bsesn <-world_markets_data$BSESN
## Get subset of data
bsesn_df <- bsesn['2015-04/2017-03']; m=length(bsesn_df$BSESN.Open);
bsesn_ophlc <- bsesn_df[,c("BSESN.Open","BSESN.High","BSESN.Low","BSESN.Close")]
# Fill in missing values with previous value
bsesn_ophlc$BSESN.Open <- zoo::na.locf(bsesn_ophlc$BSESN.Open, na.rm = FALSE)
bsesn_ophlc$BSESN.High <- zoo::na.locf(bsesn_ophlc$BSESN.High, na.rm = FALSE)
bsesn_ophlc$BSESN.Low <- zoo::na.locf(bsesn_ophlc$BSESN.Low, na.rm = FALSE)
bsesn_ophlc$BSESN.Close <- zoo::na.locf(bsesn_ophlc$BSESN.Close, na.rm = FALSE)
## Calculate volatility (regular estimations)
######################
vClose <- TTR::volatility(bsesn_ophlc, n=252,calc="close",N=252)
vParkinson <- TTR::volatility(bsesn_ophlc, n= 252,calc="parkinson",N=252)
vGK <- TTR::volatility(bsesn_ophlc, n= 252,calc="garman",N=252)
## Calculate EMA using TTR
######################
returns <-diff(bsesn_ophlc$BSESN.Close)
log_returns <- diff(log(bsesn_ophlc$BSESN.Close))
log_returns_squared <- log_returns^2
vEMA <- TTR::EMA(log_returns_squared, ratio=0.06, N=252)
vEMA <- sqrt(vEMA) * sqrt(252)  # Convert to annualized volatility
vEMA[m] # 0.09
# Create a data frame of results
volatility_measures <- data.frame(
Close = vClose[m],
Parkinson = vParkinson[m],
Garman_Klass = vGK[m],
EMA = vEMA[m]
)
print(volatility_measures)
# Combine the xts objects into a single xts object
combined_xts <- merge(vClose, vParkinson, vGK, vEMA)
combined_xts <- combined_xts['2016-04/2017-03']
# Convert the xts object to a data frame for ggplot
df_combined <- data.frame(Date = index(combined_xts), coredata(combined_xts))
# Melt the data frame for ggplot2
df_melted <- melt(df_combined, id = "Date")
# Plot using ggplot2
ggplot(df_melted, aes(x = Date, y = value, color = variable)) +
geom_line() +
labs(title = "Volatity of BSESN",
x = "Date", y = "Value", color = "Variables") +
theme_minimal()
